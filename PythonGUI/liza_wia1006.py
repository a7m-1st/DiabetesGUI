# -*- coding: utf-8 -*-
"""LIZA WIA1006.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DWPOxnHZW7lYrC9xf2hcxPBjG8jYYhdV
"""

import pandas as pd

#UPload to github, then get the raw url
diab_data = pd.read_csv('https://raw.githubusercontent.com/a7m-1st/UniJava/main/L1Q2/diabetes.csv')
print(diab_data)
X = diab_data.drop(columns='Outcome', axis = 1) #Take the X as the sample output
y = diab_data['Outcome'] #to Map feature X to house prices y

#VISUALIZE DATA HERE - ALYSSA
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

diab_data = pd.read_csv('https://raw.githubusercontent.com/a7m-1st/UniJava/main/L1Q2/diabetes.csv')


diab_data.describe()

"""AHMED WITH CLEANING THE DATASET"""

#CLEAN DATA HERE - A7MED
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# plt.show()


#a function to remove outlier using IQR method
def remove_outliers_iqr(data, column):
  q1 = data[column].quantile(0.25)
  q3 = data[column].quantile(0.75)
  iqr = q3 - q1
  lower_bound = q1 - 1.5 * iqr
  upper_bound = q3 + 1.5 * iqr
  return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]

  #remove the outliers for each column except the last one
  columns_to_check = diab_data.columns[:-1]
  for column in columns_to_check:
    diab_data = remove_outliers_iqr(diab_data, column)

  #print the cleaned dataset
  print(diab_data.head())  


columns_to_check = diab_data.columns[:-1]
for column in columns_to_check:
    diab_data = remove_outliers_iqr(diab_data, column)



#plot box for the Glucose column

# plt.show()
diab_data.describe()

"""MUNTAHA WITH SCALING THE DATA"""

#SCALE DATA HERE - MUNTAHA
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt


scaler = MinMaxScaler()
diab_data = scaler.fit_transform(diab_data)
diab_data = pd.DataFrame(diab_data, columns=['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Outcome'])
# sns.pairplot(diab_data)
diab_data.describe().round(2)



diab_data = pd.DataFrame(diab_data, columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Outcome'])


# diab_data.describe().round(2)
diab_data.describe()

#Scaling the input data to increase efficiency
scaler = StandardScaler()
diab_data = scaler.fit_transform(diab_data)

"""Placing the data in a dataframe after scaling"""

diab_data = pd.DataFrame(diab_data, columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Outcome'])
diab_data['Outcome'][diab_data['Outcome'] >= 0.5] = 1
diab_data['Outcome'][diab_data['Outcome'] < 0.5] = 0

X = diab_data.drop(columns='Outcome', axis = 1) #Take the X as the sample output
y = diab_data['Outcome']  #to Map feature X to house prices y

diab_data

"""Me with implementing models"""

#IMPLEMENT MODELS HERE - LEADER
import numpy
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn import metrics


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)

polyfit = numpy.polyfit(X_train['Insulin'], y_train, 15) #The machine learning part , finds best coeficients
mymodel = numpy.poly1d(polyfit) #Combines the Coeficients to get Output formula | Y equation
prediction = mymodel(X_test['Insulin'])

models = []
models.append(mymodel)


error = np.sqrt(mean_squared_error(y_test,prediction)) #calculate rmse
print('Mean squared error for test is', error)


prediction[prediction >= 0.5] = 1
prediction[prediction < 0.5] = 0

#Show accuracy of Model
Accuracy = accuracy_score(y_test, prediction)
print('Accuracy of the model is ',round(Accuracy, 4)* 100)

#Display confusion matrix
# confusion_matrix = metrics.confusion_matrix(y_test, prediction)
# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
# cm_display.plot()
# plt.show()

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score
from random import randint

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)  #splits the input & output into testing and training parts

ran = randint(1, 100)
ran2 = randint(1, 100)
print(ran, ran2)
model = DecisionTreeClassifier(random_state=ran2)


model.fit(X_train, y_train) #instead you train with 80%
prediction = model.predict(X_test) #You test with 25%
models.append(model)


#Accuracy
score = accuracy_score(y_test, prediction)
print('DecisionTreeClassifier Accuracy Score es',(score*100).round(2))
score = accuracy_score(y_train, model.predict(X_train))
print('Training DecisionTreeClassifier Accuracy es',(score*100).round(2))

from sklearn import neighbors

#KNN regression model with 
model = neighbors.KNeighborsRegressor(n_neighbors=16)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)  #splits the input & output into testing and training parts


# with sklearn
model.fit(X_train, y_train)
prediction = model.predict(X_test)
models.append(model)


prediction[prediction >= 0.5] = 1
prediction[prediction < 0.5] = 0

Accuracy = accuracy_score(y_test, prediction)
print('Accuracy of the model is ',round(Accuracy, 4)* 100)

#Display confusion matrix
# confusion_matrix = metrics.confusion_matrix(y_test, prediction)
# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
# cm_display.plot()
# plt.show()

#NOTE: if you want
from sklearn import linear_model
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score
from sklearn import metrics


X = diab_data.drop(columns='Outcome', axis = 1)
y = diab_data['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)  #splits the input & output into testing and training parts

#Linear Regression
regr = linear_model.LinearRegression()
regr.fit(X_train, y_train)
prediction = regr.predict(X_test)
models.append(regr)



prediction[prediction >= 0.5] = 1
prediction[prediction < 0.5] = 0

Accuracy = accuracy_score(y_test, prediction)
print('Accuracy of the model is ',round(Accuracy, 4)* 100)

#Display confusion matrix
# confusion_matrix = metrics.confusion_matrix(y_test, prediction)
# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
# cm_display.plot()
# plt.show()

import numpy
from sklearn import linear_model

#Reshaped for Logistic function.
X = diab_data.drop(columns='Outcome', axis = 1)
y = diab_data['Outcome']
y[y >= 0.5] = 1
y[y < 0.5] = 0

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)  #splits the input & output into testing and training parts

logr = linear_model.LogisticRegression()
logr.fit(X_train, y_train)
models.append(logr)


prediction = logr.predict(X_test)

#Accuracy of model
Accuracy = accuracy_score(y_test, prediction)
print('Accuracy of the model is ',round(Accuracy, 4)* 100)


#Display confusion matrix
# confusion_matrix = metrics.confusion_matrix(y_test, prediction)
# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
# cm_display.plot()
# plt.show()

import joblib
#Exporting models in `models`

# for i in range(len(models)):
#   joblib.dump(value=[models[i], scaler], filename='PythonGUI\\models\\model'+str(i))



"""Spike with Neural Networks"""

# libs import
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import seaborn as sns
import matplotlib.pyplot as plt
import torchsummary
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from torch.utils.data import DataLoader, TensorDataset

# Data Preparation
df = pd.read_csv('https://raw.githubusercontent.com/a7m-1st/UniJava/main/L1Q2/diabetes.csv')
features = df.drop('Outcome', axis = 1).values
labels = df['Outcome'].values

#Standardize the features
scaler = StandardScaler()
features = scaler.fit_transform(features)
# Train-Test split
X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, random_state=42)

# Check if cuda is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # Check for GPU availability
device

# MLP Model Definition
class DiabetesClassifierMLP(nn.Module):
  def __init__(self, input_size):
    super(DiabetesClassifierMLP, self).__init__()
    self.fc1 = nn.Linear(input_size, 64)
    self.fc2 = nn.Linear(64, 64)
    self.fc3 = nn.Linear(64, 64)
    self.fc4 = nn.Linear(64, 2) # Two classes: negative and positive

  def forward(self, x):
    x = torch.relu(self.fc1(x))
    x = torch.relu(self.fc2(x))
    x = torch.relu(self.fc3(x))
    x = self.fc4(x)
    return x

# Model Training
input_size = X_train.shape[1]
model = DiabetesClassifierMLP(input_size).to(device)
critierion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

models.append(model)

num_epochs = 76
batch_size = 32

train_losses = []
val_loss_values = []
test_accuracies = []

for epoch in range(num_epochs):
    running_loss = 0.0

    for i in range(0, len(X_train), batch_size):
        inputs = torch.Tensor(X_train[i:i + batch_size]).to(device)
        labels = torch.LongTensor(y_train[i:i + batch_size]).to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = critierion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        model.eval()
        val_outputs = model(torch.Tensor(X_test).to(device))
        val_loss = critierion(val_outputs, torch.LongTensor(y_test).to(device))

        # Store the training and validation loss values
        train_losses.append(loss.item())
        val_loss_values.append(val_loss.item())

    # Print the average loss for each epoch
    print(f"Epoch {epoch+1}/{num_epochs} - Train Loss: {loss.item():.4f} - Val Loss: {val_loss.item():.4f}")


    # Print the average loss for each epoch
    avg_loss = running_loss / (len(X_train) / batch_size)
    train_losses.append(avg_loss)

# Print the model summary
summary = torchsummary.summary(model, input_size=(input_size,))

# Model Evaluation
with torch.no_grad():
    inputs = torch.Tensor(X_test).to(device)
    labels = torch.LongTensor(y_test).to(device)



    outputs = model(inputs)
    _, predicted = torch.max(outputs.data, 1)
    predicted = torch.Tensor(predicted).to(device)
    # Calculate metrics
    inputs = torch.Tensor.cpu(inputs)
    labels = torch.LongTensor.cpu(labels)
    predicted = torch.Tensor.cpu(predicted)
    accuracy = (predicted == labels).sum().item() / len(labels)

    precision = precision_score(labels, predicted)
    recall = recall_score(labels, predicted)
    f1 = f1_score(labels, predicted)

    test_accuracies.append(accuracy)

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")


# Plot Accuracy Graph
actual_labels = labels  # Actual patients labels
predicted_labels = predicted  # Predicted patients labels

# Count the occurrences of each label
actual_counts = np.bincount(actual_labels)
predicted_counts = np.bincount(predicted_labels)

# Create x-axis positions for the bars
x = np.arange(len(actual_counts))

# Set the width of the bars
width = 0.1

# Create a figure and axis
fig, ax = plt.subplots()

# Plot the actual label counts as blue bars
ax.bar(x - width/2, actual_counts, width, color='blue', label='Actual')

# Plot the predicted label counts as orange bars
ax.bar(x + width/2, predicted_counts, width, color='orange', label='Predicted')

# Set axis labels and title
ax.set_xlabel('Diabetes Prediction Result')
ax.set_ylabel('Cases')
ax.set_title('Actual vs Predicted Diabetes Compare')

# Set x-axis tick labels
ax.set_xticks(x)
ax.set_xticklabels(['Negative', 'Positive'])

# Add a legend
ax.legend()

#Save Model
# PATH = "PythonGUI\\models\\model5.pth"
# torch.save(model.state_dict(), PATH)

model_scripted = torch.jit.script(model) # Export to TorchScript
model_scripted.save('PythonGUI\\models\\model5.pt') # Save

# Show the plot
# plt.show()

#Display confusion matrix
from sklearn import metrics
confusion_matrix = metrics.confusion_matrix(labels, predicted_labels)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
cm_display.plot()
# plt.show()
